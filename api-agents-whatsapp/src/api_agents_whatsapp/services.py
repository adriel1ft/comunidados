"""
Servi√ßo de agentes para processar mensagens
"""
import logging
import os
from typing import Optional
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.tools.mcp import MultiMCPTools
from .config import settings
from .models import AgentRequest, AgentResponse
from datetime import datetime

logger = logging.getLogger(__name__)


class AgentService:
    """Gerenciador de agentes Agno com suporte a m√∫ltiplos MCPs"""
    
    def __init__(self):
        self.agent = None
        self.mcp_context = None
        self._initialize_agent()
    
    def _initialize_agent(self):
        """Inicializa o agente com modelo OpenAI e ferramentas MCP"""
        try:
            logger.info("üöÄ Inicializando Agente Agno...")
            
            self.agent = Agent(
                model=OpenAIChat(
                    id=settings.agent_model,
                    api_key=settings.openai_api_key,
                ),
                markdown=True,
            )
            logger.info("‚úÖ Agente Agno inicializado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar agente: {e}")
            raise
    
    async def _setup_mcp_tools(self) -> Optional[MCPTools]:
        """
        Configura conex√£o com servidor MCP de Projetos de Lei
        
        Returns:
            MCPTools conectado ou None se falhar
        """
        mcp_tools_list = []

        try:
            logger.info(f"üîå Conectando ao MCP: {settings.mcp_projetos_lei_url}")
            
            mcp_projetos_lei = MCPTools(
                transport="streamable-http",
                url=settings.mcp_projetos_lei_url
            )

            mcp_tools_list.append(mcp_projetos_lei)
            logger.info(f"‚úÖ MCP conectado com sucesso")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar ao MCP: {e}")
        
        try:
            logger.info(f"üîå Conectando ao MCP Usu√°rios: {settings.mcp_users_url}")
            mcp_users = MCPTools(
                transport="streamable-http",
                url=settings.mcp_users_url
            )
            mcp_tools_list.append(mcp_users)
            logger.info("‚úÖ MCP Usu√°rios conectado")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar MCP Usu√°rios: {e}")

        if not mcp_tools_list:
            logger.warning("‚ö†Ô∏è  Nenhum MCP dispon√≠vel, agente funcionar√° sem ferramentas")
            return None
        
        return mcp_tools_list
    
    async def process_message(self, request: AgentRequest) -> AgentResponse:
        """
        Processa uma mensagem do usu√°rio usando o agente Agno
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Resposta do agente com metadados
        """
        try:
            logger.info(f"ü§ñ Processando mensagem de {request.user_id}")
            logger.info(f"   Tipo: {request.message_type}")
            logger.info(f"   Conte√∫do: {request.user_message[:100]}...")
            
            # Construir prompt baseado no tipo de mensagem
            prompt = self._build_prompt(request)
            
            # Configurar ferramentas MCP
            mcp_tools_list = await self._setup_mcp_tools()
            
            # Executar agente com context manager se MCP dispon√≠vel
            if mcp_tools_list:
                agent_with_tools = Agent(
                    model=OpenAIChat(
                        id=settings.agent_model,
                        api_key=settings.openai_api_key,
                    ),
                    tools=[tool for tool in mcp_tools_list],
                    markdown=True
                )
                logger.info("üì§ Enviando prompt para agente...")
                response_output = await agent_with_tools.arun(input=prompt)
            else:
                # Fallback: usar agente sem tools
                logger.warning("‚ö†Ô∏è  Usando agente sem ferramentas MCP")
                response_output = await self.agent.arun(input=prompt)
            
            # Extrair texto da resposta
            response_text = self._extract_response_text(response_output)
            
            logger.info(f"‚úÖ Resposta recebida: {response_text[:80]}...")
            
            # Determinar se deve enviar √°udio
            should_send_audio = self._should_send_audio(request, response_output)
            
            # Criar resposta
            response = AgentResponse(
                session_id=request.session_id,
                user_id=request.user_id,
                response_text=response_text,
                auxiliary_text=self._get_auxiliary_text(should_send_audio),
                should_send_audio=should_send_audio,
                timestamp=datetime.now(),
            )
            
            logger.info(
                f"‚úÖ Resposta gerada para {request.user_id} "
                f"(√°udio: {should_send_audio})"
            )
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar mensagem: {e}")
            logger.exception("Traceback completo:")
            raise
    
    def _extract_response_text(self, response_output) -> str:
        """
        Extrai o texto da resposta do agente
        
        Args:
            response_output: Output do agente (pode ter v√°rios formatos)
            
        Returns:
            Texto extra√≠do
        """
        # Tentar diferentes atributos comuns
        if hasattr(response_output, 'content'):
            text = response_output.content
        elif hasattr(response_output, 'message'):
            text = response_output.message
        elif hasattr(response_output, 'text'):
            text = response_output.text
        elif isinstance(response_output, dict):
            text = response_output.get('content') or response_output.get('message') or str(response_output)
        elif isinstance(response_output, str):
            text = response_output
        else:
            text = str(response_output)
        
        # Garantir que n√£o retorna None
        return text.strip() if text else "Desculpe, n√£o consegui processar sua mensagem no momento."
    
    def _build_prompt(self, request: AgentRequest) -> str:
        """
        Constr√≥i o prompt para o agente baseado na requisi√ß√£o
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            Prompt formatado para o agente
        """
        base_prompt = f"""Voc√™ √© um assistente especializado em legisla√ß√£o brasileira e projetos de lei do Congresso Nacional.

üìã CONTEXTO DA MENSAGEM:
- Tipo: {request.message_type}
- Usu√°rio: {request.user_id}
- Session: {request.session_id}

üí¨ MENSAGEM DO USU√ÅRIO:
{request.user_message}

üìã INSTRU√á√ïES PARA RESPOSTA:
1. Use as ferramentas MCP dispon√≠veis para buscar informa√ß√µes atualizadas sobre projetos de lei
2. Responda de forma clara, objetiva e acess√≠vel (evite jarg√£o t√©cnico excessivo)
3. Estruture a resposta com:
   - Resposta direta √† pergunta
   - Contexto e background relevante
   - Links √∫teis quando apropriado (e-Cidadania, C√¢mara dos Deputados)
4. Se encontrar m√∫ltiplos projetos relevantes, resuma os 3 principais
5. Cite as fontes de informa√ß√£o
6. Mantenha tom profissional mas amig√°vel
7. Se a pergunta n√£o est√° relacionada a legisla√ß√£o, redirecione gentilmente

‚öôÔ∏è INFORMA√á√ïES DO USU√ÅRIO:"""
        
        # Adicionar prefer√™ncias do usu√°rio se dispon√≠veis
        if request.user_preferences:
            if request.user_preferences.get("topics"):
                topics = ", ".join(request.user_preferences["topics"])
                base_prompt += f"\n- T√≥picos de interesse: {topics}"
            
            if request.user_preferences.get("prefer_audio"):
                base_prompt += "\n- Prefer√™ncia: Respostas em √°udio (responda concisamente)"
        
        base_prompt += "\n\nAGORA, responda √† mensagem do usu√°rio:"
        
        return base_prompt
    
    def _get_auxiliary_text(self, should_send_audio: bool) -> Optional[str]:
        """
        Retorna texto auxiliar para TTS se necess√°rio
        
        Args:
            should_send_audio: Se deve enviar √°udio
            
        Returns:
            Texto auxiliar ou None
        """
        if not should_send_audio:
            return None
        
        return (
            "üì¢ Esta resposta foi gerada pelo assistente de IA do DevsImpacto. "
            "Para mais informa√ß√µes, visite e-Cidadania.camara.leg.br"
        )
    
    def _should_send_audio(self, request: AgentRequest, response_output) -> bool:
        """
        Determina se a resposta deve ser enviada em √°udio
        
        Args:
            request: Requisi√ß√£o do agente
            
        Returns:
            True se deve enviar √°udio
        """
        if "should_send_audio" in dir(response_output):
            if response_output.should_send_audio:
                return True
        
        if "content" in dir(response_output):
            if "should_send_audio" in response_output.content.lower():
                return True

        # L√≥gica 1: Se a mensagem original foi √°udio
        if request.message_type == "audio":
            return True
        
        # L√≥gica 2: Se o usu√°rio tem prefer√™ncia de √°udio
        if request.user_preferences:
            if request.user_preferences.get("prefer_audio"):
                return True
        
        return False


# Inst√¢ncia global do servi√ßo
agent_service = AgentService()